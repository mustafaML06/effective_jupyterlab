{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TEMEL FONKSIYONLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERI SETINI INDIRME VE ILK BAKIS\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('planets')\n",
    "df = df.copy()\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('coronavirus_dataset.csv')\n",
    "df = pd.read_csv('../data/application_test.csv')\n",
    "\n",
    "\n",
    "df.head()\n",
    "df.dtypes\n",
    "df.index\n",
    "df.info()\n",
    "df.shape\n",
    "df.columns\n",
    "df.describe().T     ~~~ df.describe(include = 'all').T\n",
    "df.rename(index={0: \"a\", 1: \"b\", 2: \"c\",3:'d'})\n",
    "df.rename(columns={\"method\": \"NewMethod\", \"number\": \"NewNumber\"},errors=\"raise\")\n",
    "df.rename(columns={\"Country.Region\": \"Country_Region\",'Province.State': 'Province_State'}, inplace=True)\n",
    "df.drop(columns=['number'], inplace=True)      ~~ 'number' columnunu silme (inplace=True kalici silme)\n",
    "df.tail()\n",
    "import pandas as pd\n",
    "df.method = pd.Categorical(df.method) ~~ object to categorical\n",
    "\n",
    "import numpy as np \n",
    "df[\"yeni_day\"] = np.where(df[\"day\"].str.contains(\"Sun\"), 1, 0)  ~~ Yeni deger uretme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## toplulastirma ve gruplama --  AGGREGATION !!!\n",
    "df = sns.load_dataset('planets')\n",
    "df.head()\n",
    "df['mass'].mean()        ~~  'mass' degiskeninin ortalamasini verir\n",
    "df['distance'].max()     ~~  'distance' degiskeninin max verisini verir\n",
    "df.groupby('method')     ~~  ilk olark 'method'  kartegorik degiskenine groupby cekmemiz gerek!!!  \n",
    "df.groupby('method')['orbital_period'].mean()   ~~ groupbydan sonra mec yapcagimiz degiskeni sectik ve ortalamasini getirdik.\n",
    "df.groupby('method')['orbital_period'].describe()\n",
    "\n",
    "import numpy as np  ~~ numpydan median fonksiyonunu isteyecegimiz icin once numpy i indiriyoruz.\n",
    "df.groupby(\"gruplar\").aggregate([min, np.median, max]) ~~ Gruplanan degiskeni alarak diger TUM degiskenlerin (min, median, max) degerlerini getirmesini istiyoruz.\n",
    "df.groupby(\"gruplar\").aggregate({\"degisken1\": \"min\", \"degisken2\": \"max\"}) ~~ Herbir Degiskene farkli fonksiyon uygulamak istedigimizde...\n",
    "df.groupby('method').aggregate({'number': max, 'orbital_period':np.median}) ~~ 'method' deg. gruplar ve 'number' da max, 'orb_period' da median i getirir.\n",
    "df.groupby(['Province.State','Country.Region'])['cases'].describe()\n",
    "df.groupby(['Province.State','Country.Region','type'])['cases'].describe()\n",
    "\n",
    "#Filtreleme\n",
    "def filter_func(x):\n",
    "    return x['cases'].min()>30            ~~~ Filtreleme icin istersek kendimiz bir fonksion tanimlayabilriz\n",
    "df.groupby('cases').filter(filter_func)   ~~~ Ve tanimlanan fonksiyonu filtrelemek icin kullaniriz\n",
    "\n",
    "\n",
    "# pvottable\n",
    "df.pivot_table(\"cases\", index = \"date\", columns = \"Country.Region\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EKSIK GOZLEM (DEGER)\n",
    "df.isnull().values.any() ~~(Hic eksik deger var mi?)\n",
    "df.isnull().sum()        ~~(TOPLAM eksik degeri gorme)\n",
    "missing_values_table(credit_card_balance)   ~~ (Tum Data setindeki toplam eksik gozlemi colums colums verir!!!)\n",
    "df['degisken_ismi'].fillna(0, inplace = True)  ~~tum degiskendeki eksik degerlere toptan 0 cakma\n",
    "df['degisken_ismi'].fillna(df.degisken_ismi.mean(), inplace = True)  ~~ eksik degiskene ortalamayi atama\n",
    "df.fillna(df.mean(), inplace = True)     ~~tum df e ortalama deger atama islemi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KATEGORIK DEGISKEN OZETLERI (SINIFLARA, SAYILARA VE SINIFLARA ULASMA)(object/Category)\n",
    "# .select_dtypes / value_counts()\n",
    "import seaborn as sns \n",
    "planets = sns.load_dataset(\"planets\")\n",
    "df = planets.copy()\n",
    "df.head()\n",
    "\n",
    "kat_df = df.select_dtypes(include = [\"object\"])      ~~ kategorik degiskeni getirir\n",
    "kat_df.method.unique()                     ~~ degiskendeki siniflarin adlarina ulasiriz\n",
    "kat_df[\"method\"].value_counts().count()    ~~ degiskenin kac adet sinif olduguna ulasiriz \n",
    "kat_df[\"method\"].value_counts()            ~~ degiskenin (sinif frekanslarina) tüm benzersiz değerlerin sayısını verir\n",
    "df[\"method\"].value_counts().plot.barh();   ~~ kategorik degiskeni tablolastirir (barh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUREKLI DEGISKENLER\n",
    "import seaborn as sns \n",
    "planets = sns.load_dataset(\"planets\")\n",
    "df = planets.copy()\n",
    "df.head()\n",
    "\n",
    "df_num = df.select_dtypes(include = [\"float64\", \"int64\"])   ~~ tum sayisal degerlere ulasmak icin\n",
    "df_num.head()\n",
    "df_num['distance'].describe()      ~~ Bir 'degiskenin' betimlemesi icin  \n",
    "df['distance'].describe()\n",
    "\n",
    "Ozellestirmeler Yapilabilir\n",
    "print(\"Ortalama: \" + str(df_num[\"distance\"].mean()))\n",
    "print(\"Dolu Gözlem Sayısı: \" + str(df_num[\"distance\"].count())) \n",
    "print(\"Maksimum Değer: \" + str(df_num[\"distance\"].max()))\n",
    "print(\"Minimum Değer: \" + str(df_num[\"distance\"].min()))\n",
    "print(\"Medyan: \" + str(df_num[\"distance\"].median()))\n",
    "print(\"Standart Sapma: \" + str(df_num[\"distance\"].std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAGILIM GRAFIKLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorik degiskende barplot grafik\n",
    "# Sayisal degiskenlerde boxplot ve Histogram ve Violin grafigi\n",
    "# Korolasyon  \n",
    "# Cizgi grafik: mekanik verilerde makineverilerinde kull.\n",
    "# Zaman seerisi grafik :  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kategorik degiskenlerde Barplot \n",
    "import seaborn as sns\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "df = diamonds.copy()\n",
    "df.head()\n",
    "\n",
    "#TABLOLASTIRMA\n",
    "#ordinal tanımlama \n",
    "from pandas.api.types import CategoricalDtype\n",
    "cut_kategoriler = [\"Fair\",\"Good\",\"Very Good\",\"Premium\",\"Ideal\"]\n",
    "df.cut = df.cut.astype(CategoricalDtype(categories = cut_kategoriler, ordered = True))\n",
    "\n",
    "Basit tablolastirma\n",
    "df['cut'].value_counts().plot.barh();     ~~~tablolastirma \n",
    "df[\"cut\"].value_counts().plot.barh().set_title(\"Cut Değişkeninin Sınıf Frekansları\");   ~~~ baslikla tablolastirm\n",
    "\n",
    "Tablolastirmalarda DAHA COK seaborn.barplot kullanacagiz!!!\n",
    "sns.barplot(x = \"cut\", y = df.cut.index, data= df); \n",
    "~~ yani X eksenine categorik degiskeni Y eksenine ise X eksenine yazdigimiz degiskenin frekanslarini girecegiz    \n",
    "\n",
    "# Caprazlama (Degiskenlerin birlikte degerlendirilmesi, veriden bilgiye gecis!)\n",
    "# sns.catplot\n",
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "df = diamonds.copy()\n",
    "cut_kategoriler = [\"Fair\",\"Good\",\"Very Good\",\"Premium\",\"Ideal\"]\n",
    "df.cut = df.cut.astype(CategoricalDtype(categories = cut_kategoriler, ordered = True))\n",
    "df.head()\n",
    "\n",
    "sns.catplot(x = \"cut\", y = \"price\", data = df);     ~~ Sade bir tablo yapma\n",
    "sns.barplot(x = \"cut\", y = \"price\", hue = \"color\", data = df);  ~~Tabloya Ucuncu bir degisken, (hue) boyut ekleme!!!\n",
    "df.groupby([\"cut\",\"color\"])[\"price\"].mean()      ~~ Tablolari dogruluyoruz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram ve yogunluk grafigi\n",
    "sns.displot()  ~~ sayisal dagilimlari gorsellestirmek icin kullanilir.\n",
    "\n",
    "\n",
    "sns.distplot(df.price, kde = False);   ~~ Sadece Histogram Grafigi \n",
    "sns.distplot(df.price, bins = 10, kde = False); ~~ \n",
    "sns.distplot(df.price);                ~~ Histogram ve Yogunluk Grafigi bir arada\n",
    "sns.distplot(df.price, hist = False);  ~~ Sadece Yogunluk Grafigi\n",
    "sns.kdeplot(df.price, shade = True);   ~~ Ici Dolu Yogunluk Grafigi (Daha iyi bir gorsel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caprazlamalar\n",
    "import seaborn as sns\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "df = diamonds.copy()\n",
    "df.head()\n",
    "\n",
    "(sns\n",
    " .FacetGrid(df,\n",
    "              hue = \"cut\",\n",
    "              height = 5,\n",
    "              xlim = (0, 10000))\n",
    " .map(sns.kdeplot, \"price\", shade= True)\n",
    " .add_legend()\n",
    ");\n",
    "\n",
    "sns.catplot(x = \"cut\", y = \"price\", hue = \"color\", kind = \"point\", data = df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot  (RESTORAN BAHSIS(tip) VERI SETI)\n",
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "df = tips.copy()\n",
    "df.head()\n",
    "\n",
    "sns.boxplot(x = df['total_bill']);  \n",
    "sns.boxplot(x = df['total_bill'], orient = 'v');     ~~ Grafigi dikey hale getirir.\n",
    "\n",
    "# Caprazlamalar\n",
    "sns.boxplot(x= 'day', y = 'total_bill', data = df);    ~~ Hangi gun daha fazla kazanms? (yapilan islem saysisi degil)\n",
    "sns.boxplot(x= 'time', y='total_bill', data = df);     ~~ Hangi saat(sabah,aksam) daha fazla kazanmis?\n",
    "sns.boxplot(x = 'size', y = 'total_bill', data = df);  ~~ Kisi sayisinin faturaya etksi?\n",
    "sns.boxplot(x = 'day', y = 'total_bill', hue = 'sex', data = df);  ~~ hue ile cinsiyetin etkisine bakariz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin\n",
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "df = tips.copy()\n",
    "df.head()\n",
    "\n",
    "sns.catplot(y = \"total_bill\", kind = \"violin\", data = df);\n",
    "sns.catplot(x='day', y = \"total_bill\", hue = 'sex', kind = \"violin\", data = df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koralosyon!!!\n",
    "# sns.scatterplot()\n",
    "\n",
    "sns.scatterplot(x = 'total_bill', y = 'tip', data = df); \n",
    "sns.scatterplot(x = 'total_bill', y = 'tip', hue = 'time', data = df); \n",
    "sns.scatterplot(x = 'total_bill', y = 'tip', hue = 'time', style = 'time', data = df);\n",
    "sns.scatterplot(x = \"total_bill\", y = \"tip\", hue= \"size\", size = \"size\", data = df); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dogrusal iliskinin Gosterilmesi\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "df = tips.copy()\n",
    "df.head()\n",
    "\n",
    "sns.lmplot(x = \"total_bill\", y = \"tip\", data = df);\n",
    "sns.lmplot(x = \"total_bill\", y = \"tip\", hue = 'smoker', data = df);\n",
    "sns.lmplot(x = \"total_bill\", y = \"tip\", hue = 'smoker', col = 'time', data = df);\n",
    "sns.lmplot(x = \"total_bill\", y = \"tip\", hue = 'smoker', col = 'time', row = 'sex', data = df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot Matrisi (Sacilim  grafigi gorseli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; \n",
    "iris = sns.load_dataset(\"iris\")\n",
    "df = iris.copy()\n",
    "df.head()\n",
    "\n",
    "sns.pairplot(df);       ~~ Veri setindeki tum sayisal degiskenlerin birbrleriyle olan iliskileri tek tek tablolastirir.\n",
    "sns.pairplot(df, kind = \"reg\", hue = \"species\");   ~~\n",
    "sns.pairplot(df, hue = \"species\");\n",
    "sns.pairplot(df, hue = \"species\", markers = [\"o\",\"s\",\"D\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "import seaborn as sns\n",
    "flights = sns.load_dataset('flights')\n",
    "df = flights.copy()\n",
    "df.head()\n",
    "\n",
    "df = df.pivot('month', 'year', 'passengers');  ~~ Tabloyu okunabilir hale getiriyoruz.Heatmap uygulamak icin gerekli\n",
    "sns.heatmap(df);\n",
    "sns.heatmap(df, annot = True, fmt = \"d\"); \n",
    "sns.heatmap(df, annot = True, fmt = \"d\", linewidths = .5);\n",
    "sns.heatmap(df, annot = True, fmt = \"d\", linewidths = .5, cbar = False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cizgi Grafik\n",
    "import seaborn as sns\n",
    "fmri = sns.load_dataset(\"fmri\")\n",
    "df = fmri.copy()\n",
    "df.head()\n",
    "\n",
    "df['timepoint'].describe().T\n",
    "df.groupby('timepoint')['signal'].count()\n",
    "df.groupby('signal').count()\n",
    "df.groupby('timepoint')['signal'].describe()\n",
    "\n",
    "## Çizgi Grafik ve Çaprazlamalar\n",
    "sns.lineplot(x = \"timepoint\", y = \"signal\", data = df);\n",
    "sns.lineplot(x = \"timepoint\", y = \"signal\", hue = \"event\", data = df);\n",
    "sns.lineplot(x = \"timepoint\", y = \"signal\", hue = \"event\", style = \"event\", data = df);\n",
    "sns.lineplot(x = \"timepoint\", \n",
    "             y = \"signal\", \n",
    "             hue = \"event\", \n",
    "             style = \"event\", \n",
    "             markers = True,  dashes = False, data = df);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit Zaman Serisi Grafiği\n",
    "\n",
    "!pip install pandas_datareader       ~~~Baska bir kutuphaneden veri indirmek icin !pip kullanilir.\n",
    "import pandas_datareader as pr\n",
    "\n",
    "df = pr.get_data_yahoo(\"AAPL\", start = \"2016-01-01\", end = \"2019-08-25\") ~~ bu tarihler arasi veriyi al\n",
    "kapanis = df[\"Close\"]                ~~~ 'Close' degiskenini basli basina ele alabilmek icin.\n",
    "kapanis.plot();                      ~~~ Basit zaman grafigi icin \n",
    "kapanis.index = pd.DatetimeIndex(kapanis.index)  ~~ indexi tarihe gore yapmak icin!!!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basit Dogrusal Resgresyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://faculty.marshall.usc.edu/gareth-james/ISL/data.html\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Advertising.csv\")\n",
    "df = df.iloc[:,1:len(df)]\n",
    "df.head() \n",
    "\n",
    "## Model kurma\n",
    "import seaborn as sns\n",
    "sns.jointplot(x = \"TV\", y = \"sales\", data = df, kind = \"reg\");\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = df[[\"TV\"]]\n",
    "y = df[[\"sales\"]]\n",
    "reg = LinearRegression()\n",
    "model = reg.fit(X, y)\n",
    "dir(model)\n",
    "model.intercept_       ~~Beta0\n",
    "model.coef_            ~~Beta1   \n",
    "model.score(X,y)       ~~ ## rkare, !!!Bagimsiz degiskenlerin bagimli degiskeni aciklamadaki orani. \n",
    "ei=yi-yi(sapka)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tahmin\n",
    "import seaborn as sns      ~~~tablo olusturmak icin blogu gir\n",
    "import matplotlib.pyplot as plt\n",
    "g = sns.regplot(df[\"TV\"], df[\"sales\"], ci=None, scatter_kws={'color':'r', 's':9})\n",
    "g.set_title(\"Model Denklemi: Sales = 7.03 + TV*0.05\")\n",
    "g.set_ylabel(\"Satış Sayısı\")\n",
    "g.set_xlabel(\"TV Harcamaları\")\n",
    "plt.xlim(-10,310)\n",
    "plt.ylim(bottom=0);\n",
    "\n",
    "Sales = 7.03 + 0.05*TV   \n",
    "model.intercept_ + model.coef_*165    ~~ beta0(sabit)+beta1(katsayi)*TV reklamlarina dusundugumuz miktar ve satisin ne olacagi?\n",
    "model.predict([[165]])                ~~ Tv reklamlarina 165 birim harcadigimizda y kadar sales olur tahmini\n",
    "\n",
    "Artiklar!!! \n",
    "Gercek degerlerle tahmin edilen degerler arasindaki FARK\n",
    "MSE: Hata Kareler Ortalaması\n",
    "RMSE: Hata Kareler Ortalamasının Karekökü\n",
    "\n",
    "y.head()\n",
    "model.predict(X)[0:6]\n",
    "gercek_y = y[0:10]\n",
    "tahmin_edilen_y = pd.DataFrame(model.predict(X)[0:10])\n",
    "hatalar = pd.concat([gercek_y, tahmin_edilen_y], axis = 1)\n",
    "hatalar.columns = [\"gercek_y\",\"tahmin_edilen_y\"]\n",
    "hatalar\n",
    "hatalar[\"hata\"] = hatalar[\"gercek_y\"] - hatalar[\"tahmin_edilen_y\"]\n",
    "hatalar[\"hata_kareler\"] = hatalar[\"hata\"]**2\n",
    "np.mean(hatalar[\"hata_kareler\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coklu Dogrusal Resgresyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://faculty.marshall.usc.edu/gareth-james/ISL/data.html\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dogRegMod/Advertising.csv\")\n",
    "df = df.iloc[:,1:len(df)]\n",
    "df.head()\n",
    "\n",
    "X = df.drop('sales', axis=1)\n",
    "y = df[[\"sales\"]]\n",
    "#Statsmodels ile model kurmak\n",
    "import statsmodels.api as sm\n",
    "\n",
    "lm = sm.OLS(y, X)\n",
    "model = lm.fit()\n",
    "model.summary()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X,y)\n",
    "model.coef_\n",
    "model.intercept_\n",
    "\n",
    "import pandas as pd                  ~~ Ornegin gazeteye [10],radioya[20],tv[30] birim verirrsek getirisi ne olur?\n",
    "yeni_veri = [[10],[20],[30]]\n",
    "yeni_veri = pd.DataFrame(yeni_veri).T\n",
    "model.predict(yeni_veri)\n",
    "\n",
    "## MSE ve RMSE ISTATISTIGI\n",
    "MSE                   ~~ Tahmin edilen degerlerle gercek degerler arasindaki birim basi yapilacak ortalama hata.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "MSE = mean_squared_error(y,model.predict(X))\n",
    "\n",
    "RMSE                  ~~ train hatası // Hata kareler ortalamasi karekoku\n",
    "import numpy as np\n",
    "RMSE = np.sqrt(MSE)    \n",
    "np.sqrt(mean_squared_error(y_train, model.predict(X_train)))   ~~ EGITIM HATASI\n",
    "np.sqrt(mean_squared_error(y_test, model.predict(X_test)))     ~~ TEST HATASI\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning / Model Dogrulama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gerekli kutuphaneler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sinama seti ~~ train ile modelmizi fit edecegiz, test ile de test edecegiz\n",
    "from sklearn.model_selection import train_test_split\n",
    ".train_test_split fonksionu ile veri setimizi kaca kac bolecegimizi belirliyoruz.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 99) \n",
    "~~0.20   %20 lik kismi test seti, geri kalan %80 lik kismi train olatrak boluyoruz.  \n",
    "\n",
    "lm = LinearRegression()         ~~ Model olustur\n",
    "model = lm.fit(X_train,y_train)\n",
    "np.sqrt(mean_squared_error(y_train,model.predict(X_train)))  ~~ Train setimizi siniyoruz/train hatasi\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))          ~~ alternatif test !!!!\n",
    "np.sqrt(mean_squared_error(y_test, model.predict(X_test)))   ~~ Test setimizi siniyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-katli CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X_train, y_train, cv = 10, scoring = 'neg_mean_squared_error')\n",
    "np.mean(-cross_val_score(model, X_train, y_train, cv = 10, scoring = 'neg_mean_squared_error')) ~~train in ort hatasi MSE\n",
    "np.sqrt(np.mean(-cross_val_score(model, X_train, y_train, cv = 10, scoring = 'neg_mean_squared_error'))) ...RMSE\n",
    "np.sqrt(np.mean(-cross_val_score(model, X, y, cv = 10, scoring = 'neg_mean_squared_error'))) ~~ Tum veri setinin CV si.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [Kategorik] degiskenleri [dummies] degiskenlere degistirme!!! \n",
    "\n",
    "df = pd.read_csv(\"Hitters.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge Regresyon TAHMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###      ~~~ Iki nesneli degiskeni 1-0 a donusturme(male-female)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "lbe = preprocessing.LabelEncoder()\n",
    "train[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\n",
    "\n",
    "###     ~~~ Bosluklari istedigimiz bir degerle (12 ile) doldurma ve yeni bir degisken turetme\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(12)    ~~~  test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean() ile ortalama(12) gorulur.\n",
    "###     ~~~ Degiskendeki veri(NaN) bos ise 0 a cevirme, dolu ise 1 e cevirme ve yeni bir degisken turetme\n",
    "train[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\n",
    "\n",
    "### Map each of the title groups to a numerical value ~~~ str degerleri numerice cevirme\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n",
    "\n",
    "train['Title'] = train['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
